{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eed6841-957d-4635-b21c-ae2777db57fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from transformers import BertModel, BertTokenizerFast, AdamW\n",
    "# AutoTokenizer, AutoModelForQuestionAnswering, BertTokenizer, BertForQuestionAnswering\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22c79575-78a5-4afd-aae0-7616e355dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path): \n",
    "    #read each file and retrieve the contexts, qustions and answers\n",
    "    with open(path, 'rb') as f:\n",
    "        raw_data = json.load(f)\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    num_q = 0\n",
    "    num_pos = 0\n",
    "    num_imp = 0\n",
    "    for group in raw_data['data']:\n",
    "        for paragraph in group['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                question       = qa['question']\n",
    "                num_q  = num_q  +1\n",
    "                #if qa['is_impossible'] == True:\n",
    "                    #num_imp = num_imp +1\n",
    "                #else:\n",
    "                    #num_pos = num_pos +1\n",
    "                for answer in qa['answers']:\n",
    "                    contexts.append(context.lower())\n",
    "                    questions.append(question.lower())\n",
    "                    answers.append(answer)\n",
    "    return num_q, num_pos, num_imp, contexts, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e1cecff-39b5-4478-8a0c-d76786656916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17841\n",
      "17841\n",
      "17841\n",
      "789\n"
     ]
    }
   ],
   "source": [
    "num_q, num_pos, num_imp, train_contexts, train_questions, train_answers = get_data('./Spoken-SQuAD-master/spoken_train-v1.1.json')\n",
    "num_questions  = num_q\n",
    "num_posible = num_pos\n",
    "num_imposible  = num_imp\n",
    "\n",
    "num_q, num_pos, num_imp, valid_contexts, valid_questions, valid_answers = get_data('./Spoken-SQuAD-master/spoken_test-v1.1.json')\n",
    "print(len(valid_contexts))\n",
    "print(len(valid_questions))\n",
    "print(len(valid_answers))\n",
    "def add_answer_end(answers, contexts):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        answer['text'] = answer['text'].lower()\n",
    "        answer['answer_end'] = answer['answer_start'] + len(answer['text'])\n",
    "\n",
    "add_answer_end(train_answers, train_contexts)\n",
    "add_answer_end(valid_answers, valid_contexts)\n",
    "\n",
    "#Text lengths to contextx\n",
    "token_lens = []\n",
    "\n",
    "for txt in train_contexts:\n",
    "    txt = txt.strip()  # remove leading and trailing whitespaces\n",
    "    token_lens.append(len(txt.split(' ')))\n",
    "  \n",
    "\n",
    "print(max(token_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9e7c6c5-9e18-4417-89bc-d2b085d06320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "37111\n",
      "['what is in front of the notre dame main building?', 'the basilica of the sacred heart at notre dame is beside to which structure?']\n",
      "['architecturally the school has a catholic character. atop the main building school dome is the golden statue of the virgin mary. immediately in front of the main building in facing it is a copper statue of christ with arms appraised with the legend and the bad meow names. next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto im mary in place of prayer and reflection. it is a replica of the grotto at lourdes france where the virgin mary reputedly appeared to st bernadette still burning eighteen fifty eight. at the end of the main drive and in a direct line that connects through three statues in the gold dome is as simple modern stone statue of mary.', 'architecturally the school has a catholic character. atop the main building school dome is the golden statue of the virgin mary. immediately in front of the main building in facing it is a copper statue of christ with arms appraised with the legend and the bad meow names. next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto im mary in place of prayer and reflection. it is a replica of the grotto at lourdes france where the virgin mary reputedly appeared to st bernadette still burning eighteen fifty eight. at the end of the main drive and in a direct line that connects through three statues in the gold dome is as simple modern stone statue of mary.']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(token_lens,  bins=20)  # density=False would make counts\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Length')\n",
    "plt.title('Distribution of Context Lengths');\n",
    "\n",
    "#Test lengths of Questions\n",
    "token_lens2 = []\n",
    "\n",
    "for txt in train_questions:\n",
    "    txt = txt.strip()  # remove leading and trailing whitespaces\n",
    "    token_lens2.append(len(txt.split(' ')))\n",
    "\n",
    "\n",
    "print(max(token_lens2))\n",
    "print(len(token_lens2))\n",
    "\n",
    "plt.hist(token_lens2,  bins=20)  # density=False would make counts\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Length')\n",
    "plt.title('Distribution of Question Lengths');\n",
    "\n",
    "MAX_LENGTH = 250\n",
    "MODEL_PATH = \"deepset/bert-base-cased-squad2\"\n",
    "\n",
    "print(train_questions[0:2])\n",
    "print(train_contexts[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2548ded-8c53-47f6-9bb3-8a60b9aa39d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "37111\n",
      "250\n",
      "507\n",
      "3236\n"
     ]
    }
   ],
   "source": [
    "tokenizerFast = BertTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "train_encodings_fast = tokenizerFast(train_questions, train_contexts,  max_length = MAX_LENGTH, truncation=True, padding=True)\n",
    "valid_encodings_fast = tokenizerFast(valid_questions,valid_contexts,  max_length = MAX_LENGTH, truncation=True, padding=True)\n",
    "\n",
    "type(train_encodings_fast)\n",
    "\n",
    "print(train_encodings_fast.keys())\n",
    "print(valid_encodings_fast.keys())\n",
    "print(len(train_encodings_fast['input_ids']))\n",
    "print(len(train_encodings_fast['input_ids'][0]))\n",
    "\n",
    "def ret_Answer_start_and_end_train(idx):\n",
    "    ret_start = 0\n",
    "    ret_end = 0\n",
    "    answer_encoding_fast = tokenizerFast(train_answers[idx]['text'],  max_length = MAX_LENGTH, truncation=True, padding=True)\n",
    "    for a in range( len(train_encodings_fast['input_ids'][idx]) -  len(answer_encoding_fast['input_ids']) ): #len(train_encodings_fast['input_ids'][0])):\n",
    "        match = True\n",
    "        for i in range(1,len(answer_encoding_fast['input_ids']) - 1):\n",
    "            if (answer_encoding_fast['input_ids'][i] != train_encodings_fast['input_ids'][idx][a + i]):\n",
    "                match = False\n",
    "                break\n",
    "            if match:\n",
    "                ret_start = a+1\n",
    "                ret_end = a+i+1\n",
    "                break\n",
    "    return(ret_start, ret_end)\n",
    "\n",
    "start_positions = []\n",
    "end_positions = []\n",
    "ctr = 0\n",
    "for h in range(len(train_encodings_fast['input_ids'])):\n",
    "    s, e = ret_Answer_start_and_end_train(h)\n",
    "    start_positions.append(s)\n",
    "    end_positions.append(e)\n",
    "    if s==0:\n",
    "        ctr = ctr + 1\n",
    "\n",
    "    \n",
    "train_encodings_fast.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "print(ctr)\n",
    "\n",
    "def ret_Answer_start_and_end_valid(idx):\n",
    "    ret_start = 0\n",
    "    ret_end = 0\n",
    "    answer_encoding_fast = tokenizerFast(valid_answers[idx]['text'],  max_length = MAX_LENGTH, truncation=True, padding=True)\n",
    "    for a in range( len(valid_encodings_fast['input_ids'][idx])  -  len(answer_encoding_fast['input_ids'])   ): #len(train_encodings_fast['input_ids'][0])):\n",
    "        match = True\n",
    "        for i in range(1,len(answer_encoding_fast['input_ids']) - 1):\n",
    "            if (answer_encoding_fast['input_ids'][i] != valid_encodings_fast['input_ids'][idx][a + i]):\n",
    "                match = False\n",
    "                break\n",
    "            if match:\n",
    "                ret_start = a+1\n",
    "                ret_end = a+i+1\n",
    "                break\n",
    "    return(ret_start, ret_end)\n",
    "\n",
    "start_positions = []\n",
    "end_positions = []\n",
    "ctr = 0\n",
    "for h in range(len(valid_encodings_fast['input_ids']) ):\n",
    "    #print(h)\n",
    "    s, e = ret_Answer_start_and_end_valid(h)\n",
    "    start_positions.append(s)\n",
    "    end_positions.append(e)\n",
    "    if s==0:\n",
    "        ctr = ctr + 1\n",
    "\n",
    "    \n",
    "valid_encodings_fast.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35868eb8-c5ea-4f72-a671-cde06d92c81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "class InputDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][i]),\n",
    "            'token_type_ids': torch.tensor(self.encodings['token_type_ids'][i]),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][i]),\n",
    "            'start_positions': torch.tensor(self.encodings['start_positions'][i]),\n",
    "            'end_positions': torch.tensor(self.encodings['end_positions'][i])\n",
    "        }\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "train_dataset = InputDataset(train_encodings_fast)\n",
    "valid_dataset = InputDataset(valid_encodings_fast)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=1)\n",
    "\n",
    "bert_model = BertModel.from_pretrained(MODEL_PATH)  #MODEL_PATH = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e562f05-7cfb-41b9-bd83-16353f5acc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QAModel, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.drop_out = nn.Dropout(0.1)\n",
    "        self.l1 = nn.Linear(768 * 2, 768 * 2)\n",
    "        self.l2 = nn.Linear(768 * 2, 2)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            self.drop_out,\n",
    "            self.l1,\n",
    "            nn.LeakyReLU(),\n",
    "            self.l2 \n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        model_output = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, output_hidden_states=True)\n",
    "        hidden_states = model_output[2]\n",
    "        out = torch.cat((hidden_states[-1], hidden_states[-3]), dim=-1)  # taking Start logits from last BERT layer, End Logits from third to last layer\n",
    "        logits = self.linear_relu_stack(out)\n",
    "        \n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        \n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "        return start_logits, end_logits\n",
    "\n",
    "model = QAModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "521a5377-ed2f-4403-8e34-60203077d257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/psilimk/.local/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def loss_fn(start_logits, end_logits, start_positions, end_positions):\n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "    start_loss = loss_fct(start_logits, start_positions)\n",
    "    end_loss = loss_fct(end_logits, end_positions)\n",
    "    total_loss = (start_loss + end_loss)/2\n",
    "    return total_loss\n",
    "\n",
    "def focal_loss_fn(start_logits, end_logits, start_positions, end_positions, gamma):\n",
    "    \n",
    "    #calculate Probabilities by applying Softmax to the Start and End Logits. Then get 1 - probabilities\n",
    "    smax = nn.Softmax(dim=1)\n",
    "    probs_start = smax(start_logits)\n",
    "    inv_probs_start = 1 - probs_start\n",
    "    probs_end = smax(end_logits)\n",
    "    inv_probs_end = 1 - probs_end\n",
    "    \n",
    "    #get log of probabilities. Note: NLLLoss required log probabilities. This is the Natural Log (Log base e)\n",
    "    lsmax = nn.LogSoftmax(dim=1)\n",
    "    log_probs_start = lsmax(start_logits)\n",
    "    log_probs_end = lsmax(end_logits)\n",
    "    \n",
    "    nll = nn.NLLLoss()\n",
    "    \n",
    "    fl_start = nll(torch.pow(inv_probs_start, gamma)* log_probs_start, start_positions)\n",
    "    fl_end = nll(torch.pow(inv_probs_end, gamma)*log_probs_end, end_positions)\n",
    "    \n",
    "    #return mean of the Loss for the start and end logits\n",
    "    return ((fl_start + fl_end)/2)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=2e-5, weight_decay=2e-2)\n",
    "scheduler = ExponentialLR(optim, gamma=0.9)\n",
    "total_acc = []\n",
    "total_loss = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad3b84d8-dcd3-4482-8158-ecb4d8c2d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, epoch):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    acc = []\n",
    "    ctr = 0\n",
    "    batch_tracker = 0\n",
    "    for batch in tqdm(dataloader, desc = 'Running Epoch '):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        out_start, out_end = model(input_ids=input_ids, \n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids)\n",
    "        #loss = loss_fn(out_start, out_end, start_positions, end_positions)  # <---BASELINE.  Cross Entropy Loss is returned by Default\n",
    "        loss = focal_loss_fn(out_start, out_end, start_positions, end_positions,1) #using gamma = 1\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        start_pred = torch.argmax(out_start, dim=1)\n",
    "        end_pred = torch.argmax(out_end, dim=1)\n",
    "            \n",
    "        acc.append(((start_pred == start_positions).sum()/len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_positions).sum()/len(end_pred)).item())\n",
    "        #ctr = ctr +1\n",
    "        #if ctr==50:\n",
    "        #    break\n",
    "        batch_tracker = batch_tracker + 1\n",
    "        if batch_tracker==250 and epoch==1:\n",
    "            total_acc.append(sum(acc)/len(acc))\n",
    "            loss_avg = sum(losses)/len(losses)\n",
    "            total_loss.append(loss_avg)\n",
    "            batch_tracker = 0\n",
    "    scheduler.step()\n",
    "    ret_acc = sum(acc)/len(acc)\n",
    "    ret_loss = sum(losses)/len(losses)\n",
    "    return(ret_acc, ret_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab1dd2dd-b423-45b7-aec9-c00c9ef25113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    acc = []\n",
    "    ctr = 0\n",
    "    answer_list=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc = 'Running Evaluation'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            start_true = batch['start_positions'].to(device)\n",
    "            end_true = batch['end_positions'].to(device)\n",
    "            \n",
    "            out_start, out_end = model(input_ids=input_ids, attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "            # print(\"out_start\",out_start.shape)\n",
    "            start_pred = torch.argmax(out_start)\n",
    "            end_pred = torch.argmax(out_end)\n",
    "            answer = tokenizerFast.convert_tokens_to_string(tokenizerFast.convert_ids_to_tokens(input_ids[0][start_pred:end_pred]))\n",
    "            tanswer = tokenizerFast.convert_tokens_to_string(tokenizerFast.convert_ids_to_tokens(input_ids[0][start_true[0]:end_true[0]]))\n",
    "            answer_list.append([answer,tanswer])\n",
    "        #ret_loss = sum(losses)/len(losses)\n",
    "    return answer_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74baaf87-9d30-459e-a30c-84713df6fd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Epoch :   8%|â–Š         | 190/2320 [01:06<12:19,  2.88it/s]"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "wer = load(\"wer\")\n",
    "EPOCHS = 3\n",
    "model.to(device)\n",
    "wer_list=[]\n",
    "for epoch in range(EPOCHS):\n",
    "    train_acc, train_loss = train_epoch(model, train_data_loader, epoch+1)\n",
    "    print(f\"Train Accuracy: {train_acc}      Train Loss: {train_loss}\")\n",
    "    answer_list = eval_model(model, valid_data_loader)\n",
    "    pred_answers=[]\n",
    "    true_answers=[]\n",
    "    for i in range(len(answer_list)):\n",
    "        if(len(answer_list[i][0])==0):\n",
    "            answer_list[i][0]=\"$\"\n",
    "        if(len(answer_list[i][1])==0):\n",
    "            answer_list[i][1]=\"$\"\n",
    "        pred_answers.append(answer_list[i][0])\n",
    "        true_answers.append(answer_list[i][1])\n",
    "    wer_score = wer.compute(predictions=pred_answers, references=true_answers)\n",
    "    wer_list.append(wer_score)\n",
    "print(wer_list)\n",
    "\n",
    "tokens = tokenizerFast.tokenize(\"This is a sentence.\")\n",
    "print(tokens)\n",
    "output = tokenizerFast.convert_tokens_to_string(tokens)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f7226f-53b9-4a72-b24d-5dc736766215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
